{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 3: ???\n",
    "- TODO: fill in with Prof's description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLANNING\n",
    "\n",
    "DATA PREP\n",
    "- stratified split \n",
    "\n",
    "ML METHODS\n",
    "- Binary classification\n",
    "- Multiclass classification\n",
    "- KNN?\n",
    "\n",
    "EVALUATION\n",
    "- Confusion Matrix: TP, FP, TN, FN, FP\n",
    "  - Then F1 and stuff...????\n",
    "\n",
    "SOURCE\n",
    "- https://www.learndatasci.com/glossary/binary-classification/ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* TODO - it's only 3 seconds.. it should be fine to import all of it right?\n",
    "#import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP\n",
    "\n",
    "### Import DF \n",
    "- From the CSV file I created in my Phase 2 (EDA) notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_path = c:\\Users\\GlaDOS\\Documents\\GitHub\\eugene_data606\\output\\oasis_cross-sectional_filtered.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M/F</th>\n",
       "      <th>Age</th>\n",
       "      <th>Educ</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>CDR</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1344</td>\n",
       "      <td>0.743</td>\n",
       "      <td>1.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>73</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1454</td>\n",
       "      <td>0.708</td>\n",
       "      <td>1.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1588</td>\n",
       "      <td>0.803</td>\n",
       "      <td>1.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1737</td>\n",
       "      <td>0.848</td>\n",
       "      <td>1.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  M/F  Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF\n",
       "0   F   74   2.0  3.0  29.0  0.0  1344  0.743  1.306\n",
       "1   F   55   4.0  1.0  29.0  0.0  1147  0.810  1.531\n",
       "2   F   73   4.0  3.0  27.0  0.5  1454  0.708  1.207\n",
       "3   M   28   NaN  NaN   NaN  NaN  1588  0.803  1.105\n",
       "4   M   18   NaN  NaN   NaN  NaN  1737  0.848  1.010"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get current file path\n",
    "current_path = os.getcwd()\n",
    "parent_file_path = os.path.dirname(current_path)\n",
    "\n",
    "# Construct desired file path\n",
    "file_path = f'{parent_file_path}\\\\output\\\\oasis_cross-sectional_filtered.csv'\n",
    "print('file_path =', file_path)\n",
    "\n",
    "#* TODO Rename column names??\n",
    "#* TODO -- set datatypes?\n",
    "# Read CSV into Pandas, use the file path defined above, set row 0 as the header, and column 0 as the index\n",
    "df = pd.read_csv(file_path, \n",
    "                 header = 0, \n",
    "                 index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns\n",
    "- Elaborate on the full names according to the metadata descriptions provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['M/F', 'Age', 'Educ', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reference\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Socioeconomic Status</th>\n",
       "      <th>Mini-Mental State Examination</th>\n",
       "      <th>Clinical Dementia Rating</th>\n",
       "      <th>Estimated total intracranial volume (mm^3)</th>\n",
       "      <th>Normalized whole brain volume</th>\n",
       "      <th>Atlas scaling factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1344</td>\n",
       "      <td>0.743</td>\n",
       "      <td>1.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>73</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1454</td>\n",
       "      <td>0.708</td>\n",
       "      <td>1.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1588</td>\n",
       "      <td>0.803</td>\n",
       "      <td>1.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1737</td>\n",
       "      <td>0.848</td>\n",
       "      <td>1.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>M</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1469</td>\n",
       "      <td>0.847</td>\n",
       "      <td>1.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1684</td>\n",
       "      <td>0.790</td>\n",
       "      <td>1.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1580</td>\n",
       "      <td>0.856</td>\n",
       "      <td>1.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.861</td>\n",
       "      <td>1.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1283</td>\n",
       "      <td>0.834</td>\n",
       "      <td>1.368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>436 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender  Age  Education  Socioeconomic Status  \\\n",
       "0        F   74        2.0                   3.0   \n",
       "1        F   55        4.0                   1.0   \n",
       "2        F   73        4.0                   3.0   \n",
       "3        M   28        NaN                   NaN   \n",
       "4        M   18        NaN                   NaN   \n",
       "..     ...  ...        ...                   ...   \n",
       "431      M   20        NaN                   NaN   \n",
       "432      M   22        NaN                   NaN   \n",
       "433      M   22        NaN                   NaN   \n",
       "434      F   20        NaN                   NaN   \n",
       "435      F   26        NaN                   NaN   \n",
       "\n",
       "     Mini-Mental State Examination  Clinical Dementia Rating  \\\n",
       "0                             29.0                       0.0   \n",
       "1                             29.0                       0.0   \n",
       "2                             27.0                       0.5   \n",
       "3                              NaN                       NaN   \n",
       "4                              NaN                       NaN   \n",
       "..                             ...                       ...   \n",
       "431                            NaN                       NaN   \n",
       "432                            NaN                       NaN   \n",
       "433                            NaN                       NaN   \n",
       "434                            NaN                       NaN   \n",
       "435                            NaN                       NaN   \n",
       "\n",
       "     Estimated total intracranial volume (mm^3)  \\\n",
       "0                                          1344   \n",
       "1                                          1147   \n",
       "2                                          1454   \n",
       "3                                          1588   \n",
       "4                                          1737   \n",
       "..                                          ...   \n",
       "431                                        1469   \n",
       "432                                        1684   \n",
       "433                                        1580   \n",
       "434                                        1262   \n",
       "435                                        1283   \n",
       "\n",
       "     Normalized whole brain volume  Atlas scaling factor  \n",
       "0                            0.743                 1.306  \n",
       "1                            0.810                 1.531  \n",
       "2                            0.708                 1.207  \n",
       "3                            0.803                 1.105  \n",
       "4                            0.848                 1.010  \n",
       "..                             ...                   ...  \n",
       "431                          0.847                 1.195  \n",
       "432                          0.790                 1.042  \n",
       "433                          0.856                 1.111  \n",
       "434                          0.861                 1.390  \n",
       "435                          0.834                 1.368  \n",
       "\n",
       "[436 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_dict = {'M/F'    : 'Gender', \n",
    "               'Educ'   : 'Education',\n",
    "               'SES'    : 'Socioeconomic Status',\n",
    "               'MMSE'   : 'Mini-Mental State Examination',\n",
    "               'CDR'    : 'Clinical Dementia Rating',\n",
    "               'eTIV'   : 'Estimated total intracranial volume (mm^3)',\n",
    "               'nWBV'   : 'Normalized whole brain volume',\n",
    "               'ASF'    : 'Atlas scaling factor'\n",
    "                }\n",
    "\n",
    "# Rename columns based on provided dictionary\n",
    "df = df.rename(columns = rename_dict)\n",
    "\n",
    "# display the updated dataframe\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "Need to replace the Gender column with dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender column has 2 unique values\n",
      "I expect 2 (for M/F data)\n"
     ]
    }
   ],
   "source": [
    "# CHECK\n",
    "print(f\"Gender column has {df['Gender'].nunique()} unique values\")\n",
    "print(f'I expect 2 (for M/F data)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the DF with the dummy version\n",
    "- 0 = female\n",
    "- 1 = male\n",
    "\n",
    "NOTES:\n",
    "- The `Gender` column has been renamed to `Gender_M` and moved to the right side of DF\n",
    "- `drop_first` --> removes the reference column generated by the `get_dummies` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Socioeconomic Status</th>\n",
       "      <th>Mini-Mental State Examination</th>\n",
       "      <th>Clinical Dementia Rating</th>\n",
       "      <th>Estimated total intracranial volume (mm^3)</th>\n",
       "      <th>Normalized whole brain volume</th>\n",
       "      <th>Atlas scaling factor</th>\n",
       "      <th>Gender_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1344</td>\n",
       "      <td>0.743</td>\n",
       "      <td>1.306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1454</td>\n",
       "      <td>0.708</td>\n",
       "      <td>1.207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1588</td>\n",
       "      <td>0.803</td>\n",
       "      <td>1.105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1737</td>\n",
       "      <td>0.848</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1469</td>\n",
       "      <td>0.847</td>\n",
       "      <td>1.195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1684</td>\n",
       "      <td>0.790</td>\n",
       "      <td>1.042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1580</td>\n",
       "      <td>0.856</td>\n",
       "      <td>1.111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.861</td>\n",
       "      <td>1.390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1283</td>\n",
       "      <td>0.834</td>\n",
       "      <td>1.368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>436 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Education  Socioeconomic Status  Mini-Mental State Examination  \\\n",
       "0     74        2.0                   3.0                           29.0   \n",
       "1     55        4.0                   1.0                           29.0   \n",
       "2     73        4.0                   3.0                           27.0   \n",
       "3     28        NaN                   NaN                            NaN   \n",
       "4     18        NaN                   NaN                            NaN   \n",
       "..   ...        ...                   ...                            ...   \n",
       "431   20        NaN                   NaN                            NaN   \n",
       "432   22        NaN                   NaN                            NaN   \n",
       "433   22        NaN                   NaN                            NaN   \n",
       "434   20        NaN                   NaN                            NaN   \n",
       "435   26        NaN                   NaN                            NaN   \n",
       "\n",
       "     Clinical Dementia Rating  Estimated total intracranial volume (mm^3)  \\\n",
       "0                         0.0                                        1344   \n",
       "1                         0.0                                        1147   \n",
       "2                         0.5                                        1454   \n",
       "3                         NaN                                        1588   \n",
       "4                         NaN                                        1737   \n",
       "..                        ...                                         ...   \n",
       "431                       NaN                                        1469   \n",
       "432                       NaN                                        1684   \n",
       "433                       NaN                                        1580   \n",
       "434                       NaN                                        1262   \n",
       "435                       NaN                                        1283   \n",
       "\n",
       "     Normalized whole brain volume  Atlas scaling factor  Gender_M  \n",
       "0                            0.743                 1.306         0  \n",
       "1                            0.810                 1.531         0  \n",
       "2                            0.708                 1.207         0  \n",
       "3                            0.803                 1.105         1  \n",
       "4                            0.848                 1.010         1  \n",
       "..                             ...                   ...       ...  \n",
       "431                          0.847                 1.195         1  \n",
       "432                          0.790                 1.042         1  \n",
       "433                          0.856                 1.111         1  \n",
       "434                          0.861                 1.390         0  \n",
       "435                          0.834                 1.368         0  \n",
       "\n",
       "[436 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(\n",
    "    df, \n",
    "    columns = ['Gender'], \n",
    "    drop_first = True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q) Should I impute for my target column (CDR)? \n",
    "\n",
    "A) That doesn't sound like a good idea..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 201 unknowns in the CDR column\n",
      "Total length of CDR = 436\n",
      "Making that 46% of the CDR column missing\n"
     ]
    }
   ],
   "source": [
    "# CHECK how many unknowns in CDR\n",
    "unknown_count = df['Clinical Dementia Rating'].isna().sum()\n",
    "print(f'There are {unknown_count} unknowns in the CDR column')\n",
    "print(f'Total length of CDR = {len(df)}')\n",
    "print(f'Making that {int(unknown_count/len(df) * 100)}% of the CDR column missing')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the target column (CDR) to the end for simpler processing later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Socioeconomic Status</th>\n",
       "      <th>Mini-Mental State Examination</th>\n",
       "      <th>Estimated total intracranial volume (mm^3)</th>\n",
       "      <th>Normalized whole brain volume</th>\n",
       "      <th>Atlas scaling factor</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Clinical Dementia Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1344</td>\n",
       "      <td>0.743</td>\n",
       "      <td>1.306</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Education  Socioeconomic Status  Mini-Mental State Examination  \\\n",
       "0   74        2.0                   3.0                           29.0   \n",
       "\n",
       "   Estimated total intracranial volume (mm^3)  Normalized whole brain volume  \\\n",
       "0                                        1344                          0.743   \n",
       "\n",
       "   Atlas scaling factor  Gender_M  Clinical Dementia Rating  \n",
       "0                 1.306         0                       0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the column I want to move\n",
    "column_name = 'Clinical Dementia Rating'\n",
    "\n",
    "# Removes this column from the original DF\n",
    "last_column = df.pop(column_name)\n",
    "\n",
    "# Insert CDR column back into the DF, but at the end\n",
    "df.insert(len(df.columns), column_name, last_column)\n",
    "\n",
    "# CHECK - is CDR last?\n",
    "df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop missing rows in target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Socioeconomic Status</th>\n",
       "      <th>Mini-Mental State Examination</th>\n",
       "      <th>Estimated total intracranial volume (mm^3)</th>\n",
       "      <th>Normalized whole brain volume</th>\n",
       "      <th>Atlas scaling factor</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Clinical Dementia Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1344</td>\n",
       "      <td>0.743</td>\n",
       "      <td>1.306</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.531</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1454</td>\n",
       "      <td>0.708</td>\n",
       "      <td>1.207</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1636</td>\n",
       "      <td>0.689</td>\n",
       "      <td>1.073</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1321</td>\n",
       "      <td>0.827</td>\n",
       "      <td>1.329</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1295</td>\n",
       "      <td>0.748</td>\n",
       "      <td>1.355</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>73</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1536</td>\n",
       "      <td>0.730</td>\n",
       "      <td>1.142</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>61</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1354</td>\n",
       "      <td>0.825</td>\n",
       "      <td>1.297</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>61</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1637</td>\n",
       "      <td>0.780</td>\n",
       "      <td>1.072</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1372</td>\n",
       "      <td>0.766</td>\n",
       "      <td>1.279</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Education  Socioeconomic Status  Mini-Mental State Examination  \\\n",
       "0     74        2.0                   3.0                           29.0   \n",
       "1     55        4.0                   1.0                           29.0   \n",
       "2     73        4.0                   3.0                           27.0   \n",
       "8     74        5.0                   2.0                           30.0   \n",
       "9     52        3.0                   2.0                           30.0   \n",
       "..   ...        ...                   ...                            ...   \n",
       "411   70        1.0                   4.0                           29.0   \n",
       "412   73        3.0                   2.0                           23.0   \n",
       "413   61        2.0                   4.0                           28.0   \n",
       "414   61        5.0                   2.0                           30.0   \n",
       "415   62        3.0                   3.0                           26.0   \n",
       "\n",
       "     Estimated total intracranial volume (mm^3)  \\\n",
       "0                                          1344   \n",
       "1                                          1147   \n",
       "2                                          1454   \n",
       "8                                          1636   \n",
       "9                                          1321   \n",
       "..                                          ...   \n",
       "411                                        1295   \n",
       "412                                        1536   \n",
       "413                                        1354   \n",
       "414                                        1637   \n",
       "415                                        1372   \n",
       "\n",
       "     Normalized whole brain volume  Atlas scaling factor  Gender_M  \\\n",
       "0                            0.743                 1.306         0   \n",
       "1                            0.810                 1.531         0   \n",
       "2                            0.708                 1.207         0   \n",
       "8                            0.689                 1.073         1   \n",
       "9                            0.827                 1.329         0   \n",
       "..                             ...                   ...       ...   \n",
       "411                          0.748                 1.355         0   \n",
       "412                          0.730                 1.142         0   \n",
       "413                          0.825                 1.297         0   \n",
       "414                          0.780                 1.072         1   \n",
       "415                          0.766                 1.279         0   \n",
       "\n",
       "     Clinical Dementia Rating  \n",
       "0                         0.0  \n",
       "1                         0.0  \n",
       "2                         0.5  \n",
       "8                         0.0  \n",
       "9                         0.0  \n",
       "..                        ...  \n",
       "411                       0.5  \n",
       "412                       0.5  \n",
       "413                       0.0  \n",
       "414                       0.0  \n",
       "415                       0.0  \n",
       "\n",
       "[235 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing values in target column (CDR)\n",
    "df.dropna(subset = ['Clinical Dementia Rating'], inplace=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split target column (CDR) into binary groups of non-demented or demented patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique values in the CDR column =\n",
      " 2 == 2?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Socioeconomic Status</th>\n",
       "      <th>Mini-Mental State Examination</th>\n",
       "      <th>Estimated total intracranial volume (mm^3)</th>\n",
       "      <th>Normalized whole brain volume</th>\n",
       "      <th>Atlas scaling factor</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Clinical Dementia Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1344</td>\n",
       "      <td>0.743</td>\n",
       "      <td>1.306</td>\n",
       "      <td>0</td>\n",
       "      <td>non-demented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.531</td>\n",
       "      <td>0</td>\n",
       "      <td>non-demented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1454</td>\n",
       "      <td>0.708</td>\n",
       "      <td>1.207</td>\n",
       "      <td>0</td>\n",
       "      <td>demented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1636</td>\n",
       "      <td>0.689</td>\n",
       "      <td>1.073</td>\n",
       "      <td>1</td>\n",
       "      <td>non-demented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1321</td>\n",
       "      <td>0.827</td>\n",
       "      <td>1.329</td>\n",
       "      <td>0</td>\n",
       "      <td>non-demented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>81</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1664</td>\n",
       "      <td>0.679</td>\n",
       "      <td>1.055</td>\n",
       "      <td>0</td>\n",
       "      <td>non-demented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>76</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1738</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1</td>\n",
       "      <td>demented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>82</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1477</td>\n",
       "      <td>0.739</td>\n",
       "      <td>1.188</td>\n",
       "      <td>1</td>\n",
       "      <td>demented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1636</td>\n",
       "      <td>0.813</td>\n",
       "      <td>1.073</td>\n",
       "      <td>1</td>\n",
       "      <td>non-demented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>89</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1536</td>\n",
       "      <td>0.715</td>\n",
       "      <td>1.142</td>\n",
       "      <td>0</td>\n",
       "      <td>non-demented</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Education  Socioeconomic Status  Mini-Mental State Examination  \\\n",
       "0    74        2.0                   3.0                           29.0   \n",
       "1    55        4.0                   1.0                           29.0   \n",
       "2    73        4.0                   3.0                           27.0   \n",
       "8    74        5.0                   2.0                           30.0   \n",
       "9    52        3.0                   2.0                           30.0   \n",
       "11   81        5.0                   2.0                           30.0   \n",
       "13   76        2.0                   NaN                           28.0   \n",
       "14   82        2.0                   4.0                           27.0   \n",
       "16   39        3.0                   4.0                           28.0   \n",
       "17   89        5.0                   1.0                           30.0   \n",
       "\n",
       "    Estimated total intracranial volume (mm^3)  Normalized whole brain volume  \\\n",
       "0                                         1344                          0.743   \n",
       "1                                         1147                          0.810   \n",
       "2                                         1454                          0.708   \n",
       "8                                         1636                          0.689   \n",
       "9                                         1321                          0.827   \n",
       "11                                        1664                          0.679   \n",
       "13                                        1738                          0.719   \n",
       "14                                        1477                          0.739   \n",
       "16                                        1636                          0.813   \n",
       "17                                        1536                          0.715   \n",
       "\n",
       "    Atlas scaling factor  Gender_M Clinical Dementia Rating  \n",
       "0                  1.306         0             non-demented  \n",
       "1                  1.531         0             non-demented  \n",
       "2                  1.207         0                 demented  \n",
       "8                  1.073         1             non-demented  \n",
       "9                  1.329         0             non-demented  \n",
       "11                 1.055         0             non-demented  \n",
       "13                 1.010         1                 demented  \n",
       "14                 1.188         1                 demented  \n",
       "16                 1.073         1             non-demented  \n",
       "17                 1.142         0             non-demented  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set bin borders for integer to categorical conversion\n",
    "bins = [0, 0.1, np.inf]\n",
    "\n",
    "#* TODO - name this as the binary DF?\n",
    "# Split the CDR into 2 groups: demented and non-demented\n",
    "df['Clinical Dementia Rating'] = df['Clinical Dementia Rating'].apply(\n",
    "    lambda x: 'non-demented' if x == 0.0 else (\n",
    "        'demented' if x == 0.5 else(\n",
    "            'demented' if x == 1 else(\n",
    "                'demented' if x == 2 else 'unknown'))))\n",
    "\n",
    "# CHECK - need to make sure that the lambda function split up CDR correctly\n",
    "print(\"# of unique values in the CDR column =\\n\", df['Clinical Dementia Rating'].nunique(), '== 2?')\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] DEFINE DATA AND TARGET VARIABLES\n",
    "\n",
    "First, get the column names as a list\n",
    "\n",
    "Then, pick the data columns and the target columns to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(data_column_list) = <class 'list'>\n",
      "data_column_list = ['Age', 'Education', 'Socioeconomic Status', 'Mini-Mental State Examination', 'Estimated total intracranial volume (mm^3)', 'Normalized whole brain volume', 'Atlas scaling factor', 'Gender_M']\n",
      "target_column_list = ['Clinical Dementia Rating']\n"
     ]
    }
   ],
   "source": [
    "# All columns besides the target column (CDR) will be used as the explanatory data columns\n",
    "data_column_list = df.columns[df.columns != 'Clinical Dementia Rating'].tolist()\n",
    "target_column_list = ['Clinical Dementia Rating']\n",
    "\n",
    "# CHECK\n",
    "print('type(data_column_list) =', type(data_column_list))\n",
    "print('data_column_list =', data_column_list )\n",
    "print('target_column_list =', target_column_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the DF up based on the predefined lists for data and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (235, 8)\n",
      "y.shape = (235, 1)\n"
     ]
    }
   ],
   "source": [
    "X = df[data_column_list]\n",
    "y = df[target_column_list]\n",
    "\n",
    "# CHECK\n",
    "print('X.shape =', X.shape)\n",
    "print('y.shape =', y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2] STRATIFIED TRAIN/TEST SPLIT\n",
    "- X = 8 data columns \n",
    "- y = 1 target column\n",
    "- test_size = 20% for testing (model evaluation) later\n",
    "- stratify = keep the ratios of outcomes in the target column the same between training/testing groups\n",
    "- random_state = 0 --> for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape: (47, 8)\n",
      "X_train.shape: (188, 8)\n",
      "y_test.shape: (47, 1)\n",
      "y_train.shape: (188, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X, \n",
    "                                        y, \n",
    "                                        test_size = 0.20,\n",
    "                                        stratify = y,\n",
    "                                        random_state = 0)\n",
    "\n",
    "# Collect all resulting datasets into 1 dictionary for simpler iterating later\n",
    "all_dfs_dict = {\n",
    "    'X_test': X_test,\n",
    "    'X_train': X_train,\n",
    "    'y_test': y_test,\n",
    "    'y_train': y_train\n",
    "}\n",
    "\n",
    "# Loop through the dictionary and print name: shape\n",
    "for key, value in all_dfs_dict.items():\n",
    "    print(f\"{key}.shape: {value.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] IMPUTE + NORMALIZE DATA\n",
    "\n",
    "Q) What order should I do this in?\n",
    "\n",
    "A) Prolly impute 1st, see: https://datascience.stackexchange.com/questions/53138/which-comes-first-multiple-imputation-splitting-into-train-test-or-standardiz\n",
    "\n",
    "### Impute missing data\n",
    "\n",
    "### CHECK\n",
    "\n",
    "Q) How much of a difference would it be if I removed all rows with any nulls?\n",
    "\n",
    "A) It will cut down the dataset around half (50%) according to my EDA notebook\n",
    "\n",
    "### TODO\n",
    "- maybe I should run both methods to check anyway?\n",
    "\n",
    "### Impute missing data in rows\n",
    "- IMPORTANT!!! --> run imputation AFTER train/test splitting\n",
    "\n",
    "TODO:\n",
    "- Impute missing data using median since most of these started as multi-class labels??? can't used mean for them anyway, and the distribution is very skewed according to my EDA notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical list of X_test = ['Age', 'Education', 'Socioeconomic Status', 'Mini-Mental State Examination', 'Estimated total intracranial volume (mm^3)', 'Normalized whole brain volume', 'Atlas scaling factor', 'Gender_M']\n",
      "X_test has nulls in:\n",
      "Socioeconomic Status    7\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "numerical list of X_train = ['Age', 'Education', 'Socioeconomic Status', 'Mini-Mental State Examination', 'Estimated total intracranial volume (mm^3)', 'Normalized whole brain volume', 'Atlas scaling factor', 'Gender_M']\n",
      "X_train has nulls in:\n",
      "Socioeconomic Status    12\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "numerical list of y_test = []\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "numerical list of y_train = []\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "# CHECK for nulls in each DF\n",
    "\n",
    "# Iterate thru every DF\n",
    "for key, value in all_dfs_dict.items():\n",
    "    #print(f'{value}')\n",
    "    \n",
    "    # Save a list of numerical (float/int) type columns\n",
    "    numerical_list = value.select_dtypes(include = 'number').columns.tolist()\n",
    "    print(f'numerical list of {key} =', numerical_list)\n",
    "    \n",
    "    # Sum up nulls in each DF\n",
    "    nulls_before = value.isnull().sum()\n",
    "    #print(nulls_before)\n",
    "    \n",
    "    # Iterate thru every row of resulting nulls counts\n",
    "    for row in nulls_before:\n",
    "        \n",
    "        # CASE #1: are any of the null counts > 0?\n",
    "        if row > 0:\n",
    "            \n",
    "            # Print name of DF and name of column\n",
    "            print(f'{key} has nulls in:')\n",
    "            print(nulls_before[nulls_before > 0])\n",
    "            \n",
    "            # CHECK numerical list???\n",
    "        \n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test numerical list = ['Age', 'Education', 'Socioeconomic Status', 'Mini-Mental State Examination', 'Estimated total intracranial volume (mm^3)', 'Normalized whole brain volume', 'Atlas scaling factor', 'Gender_M']\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "X_test nulls_before =\n",
      " Age                                           0\n",
      "Education                                     0\n",
      "Socioeconomic Status                          7\n",
      "Mini-Mental State Examination                 0\n",
      "Estimated total intracranial volume (mm^3)    0\n",
      "Normalized whole brain volume                 0\n",
      "Atlas scaling factor                          0\n",
      "Gender_M                                      0\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "X_test nulls_after =\n",
      " Age                                           0\n",
      "Education                                     0\n",
      "Socioeconomic Status                          0\n",
      "Mini-Mental State Examination                 0\n",
      "Estimated total intracranial volume (mm^3)    0\n",
      "Normalized whole brain volume                 0\n",
      "Atlas scaling factor                          0\n",
      "Gender_M                                      0\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "X_train numerical list = ['Age', 'Education', 'Socioeconomic Status', 'Mini-Mental State Examination', 'Estimated total intracranial volume (mm^3)', 'Normalized whole brain volume', 'Atlas scaling factor', 'Gender_M']\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "X_train nulls_before =\n",
      " Age                                            0\n",
      "Education                                      0\n",
      "Socioeconomic Status                          12\n",
      "Mini-Mental State Examination                  0\n",
      "Estimated total intracranial volume (mm^3)     0\n",
      "Normalized whole brain volume                  0\n",
      "Atlas scaling factor                           0\n",
      "Gender_M                                       0\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "X_train nulls_after =\n",
      " Age                                           0\n",
      "Education                                     0\n",
      "Socioeconomic Status                          0\n",
      "Mini-Mental State Examination                 0\n",
      "Estimated total intracranial volume (mm^3)    0\n",
      "Normalized whole brain volume                 0\n",
      "Atlas scaling factor                          0\n",
      "Gender_M                                      0\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "y_test numerical list = []\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "y_test nulls_before =\n",
      " Clinical Dementia Rating    0\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "y_test nulls_after =\n",
      " Clinical Dementia Rating    0\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "y_train numerical list = []\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "y_train nulls_before =\n",
      " Clinical Dementia Rating    0\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "y_train nulls_after =\n",
      " Clinical Dementia Rating    0\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "# Impute missing numerical values for each value\n",
    "\n",
    "for key, value in all_dfs_dict.items():\n",
    "    \n",
    "    # CHECK - before \n",
    "    nulls_before = value.isnull().sum()\n",
    "\n",
    "    # Save a list of numerical (float/int) type columns\n",
    "    numerical_list = value.select_dtypes(include = 'number').columns.tolist()\n",
    "    print(f'{key} numerical list =', numerical_list)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "    # Impute median values in every numerical column\n",
    "    for column in numerical_list:\n",
    "        median = value[column].median()\n",
    "        value[column].fillna(median, inplace = True)\n",
    "        \n",
    "    # CHECK - after\n",
    "    nulls_after = value.isnull().sum()\n",
    "\n",
    "    #* TODO - could try to have it check before and after \n",
    "    #! ERROR - ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()\n",
    "    \n",
    "    # if nulls_before == nulls_after:\n",
    "    #     continue\n",
    "    # else:\n",
    "        \n",
    "    # Print the before and after sum of null values\n",
    "    print(f'{key} nulls_before =\\n', nulls_before)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print(f'{key} nulls_after =\\n', nulls_after)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data\n",
    "\n",
    "Q) When should I normalize?\n",
    "\n",
    "A) When:\n",
    "- distribution is not normal --> yes\n",
    "- magnitudes are very different --> yes\n",
    "- test and find out before/after\n",
    "\n",
    "### WARNING!\n",
    "- exclude these columns from min/max scaling:\n",
    "  - target (CDR)\n",
    "  - dummies (Gender_M)\n",
    "- You should only scale CONTINUOUS # col's\n",
    "  - Mine mostly AREN'T continuous...\n",
    "  - They are discrete groups, really multi-class labels\n",
    "\n",
    "\n",
    "Q) Which are continuous numeric columns?\n",
    "\n",
    "A) These columns are:\n",
    "- Age\n",
    "- MMSE???\n",
    "- eTIV???\n",
    "- nWBV???\n",
    "- ASF???\n",
    "\n",
    "Q) Which are discrete numeric columns?\n",
    "\n",
    "A) These are discrete:\n",
    "- Educ\n",
    "- SES\n",
    "- Gender???\n",
    "\n",
    "Maybe I should use ColumnTransformer instead:\n",
    "- see: https://machinelearningmastery.com/columntransformer-for-numerical-and-categorical-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #? Q) Should I be excluding the target column?\n",
    "# #? Q) Should I use Normalizer or MinMaxScaler?\n",
    "\n",
    "# # Iterate thru the all DFs in the dictionary\n",
    "# for key, value in all_dfs_dict.items():\n",
    "    \n",
    "#     # Apply min/max scaling to each DF\n",
    "#     # min_max_scaler = MinMaxScaler()\n",
    "#     normalizedX = MinMaxScaler().fit_transform(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming your DataFrame is named 'df'\n",
    "# numeric_columns = ['num_col1', 'num_col2', 'num_col3']\n",
    "# min_max_scaler = MinMaxScaler()\n",
    "# df[numeric_columns] = min_max_scaler.fit_transform(df[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try applying the Standard Scaler\n",
    "# IMPORTANT!! -- do the train/test datasets SEPARATELY!!\n",
    "\n",
    "ss_train = StandardScaler()\n",
    "X_train = ss_train.fit_transform(X_train)\n",
    "\n",
    "ss_test = StandardScaler()\n",
    "X_test = ss_test.fit_transform(X_test)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4] FIT DATA\n",
    "- SOURCE: https://www.freecodecamp.org/news/how-to-build-and-train-linear-and-logistic-regression-ml-models-in-python/#:~:text=Training%20the%20Logistic%20Regression%20Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert both the y columns into a 1D array\n",
    "- Necessary to fix training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(y_train) = <class 'pandas.core.frame.DataFrame'>\n",
      "type(y_test) = <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# CHECK - y column dimensions\n",
    "print('type(y_train) =', type(y_train))\n",
    "print('type(y_test) =', type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(y_test) = <class 'numpy.ndarray'>\n",
      "type(y_train) = <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Convert the y column into a 1D array\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "# CHECK - conversion results\n",
    "print('type(y_test) =', type(y_test))\n",
    "print('type(y_train) =', type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of Logistic Regression\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model using my training datasets and fitting to the Logistic Regression model\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#! ERROR\n",
    "\n",
    "c:\\tools\\Anaconda3\\envs\\data601-intro_to_DS_20220604\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
    "\n",
    "  y = column_or_1d(y, warn=True)\n",
    "  \n",
    "c:\\tools\\Anaconda3\\envs\\data601-intro_to_DS_20220604\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "    \n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "    \n",
    "  n_iter_i = _check_optimize_result("
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [5] PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive(TP)  =  23\n",
      "False Positive(FP) =  6\n",
      "True Negative(TN)  =  14\n",
      "False Negative(FN) =  4\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in all_dfs_dict.items():"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE FOR LATER ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the CDR into multiclass groups denoting the severity of the dementia\n",
    "# df['CDR'] = df['CDR'].apply(\n",
    "#     lambda x: 'non-demented' if x == 0.0 else (\n",
    "#         'very mild dementia' if x == 0.5 else(\n",
    "#             'mild dementia' if x == 1 else(\n",
    "#                 'moderate dementia' if x == 2 else 'unknown'))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data601-intro_to_DS_20220604",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
